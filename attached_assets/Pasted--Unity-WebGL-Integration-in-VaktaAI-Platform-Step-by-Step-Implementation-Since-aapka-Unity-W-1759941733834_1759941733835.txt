## ğŸš€ Unity WebGL Integration in VaktaAI Platform - Step by Step Implementation

Since aapka Unity WebGL build ready hai, main aapko exact implementation steps de raha hun to integrate it in your existing VaktaAI platform:

## ğŸ“ Step 1: WebGL Files Setup

### **1.1 Place Unity WebGL Build Files**
```bash
# Your VaktaAI project structure me WebGL files place karo
client/
â”œâ”€â”€ public/
â”‚   â””â”€â”€ unity-avatar/
â”‚       â”œâ”€â”€ index.html
â”‚       â”œâ”€â”€ Build/
â”‚       â”‚   â”œâ”€â”€ UnityLoader.js
â”‚       â”‚   â”œâ”€â”€ WebGL.data
â”‚       â”‚   â”œâ”€â”€ WebGL.framework.js
â”‚       â”‚   â”œâ”€â”€ WebGL.loader.js
â”‚       â”‚   â””â”€â”€ WebGL.wasm
â”‚       â””â”€â”€ TemplateData/
â”‚           â”œâ”€â”€ style.css
â”‚           â””â”€â”€ favicon.ico
```

### **1.2 Modify Unity index.html**
Unity ke generated `index.html` ko modify karo for iframe compatibility:

```html
<!-- public/unity-avatar/index.html -->
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>VaktaAI Avatar</title>
    <style>
        body { margin: 0; padding: 0; overflow: hidden; }
        #unity-container { width: 100%; height: 100vh; }
        #unity-canvas { width: 100%; height: 100%; display: block; }
    </style>
</head>
<body>
    <div id="unity-container">
        <canvas id="unity-canvas"></canvas>
    </div>
    
    <script src="Build/WebGL.loader.js"></script>
    <script>
        var unityInstance = null;
        
        // Unity to React communication
        function SendMessageToReact(message) {
            window.parent.postMessage({
                type: 'UNITY_MESSAGE',
                payload: message
            }, '*');
        }
        
        // Unity ready notification
        function OnUnityReady() {
            window.parent.postMessage({
                type: 'UNITY_READY',
                payload: true
            }, '*');
        }
        
        // React to Unity communication listener
        window.addEventListener('message', function(event) {
            if (!unityInstance) return;
            
            // Handle different message types
            switch(event.data.type) {
                case 'PLAY_TTS_AUDIO':
                    unityInstance.SendMessage(
                        'AvatarController',
                        'PlayAudioFromBase64',
                        event.data.payload.audioData
                    );
                    break;
                    
                case 'SET_EMOTION':
                    unityInstance.SendMessage(
                        'AvatarController',
                        'SetEmotion',
                        event.data.payload.emotion
                    );
                    break;
                    
                case 'TRIGGER_GESTURE':
                    unityInstance.SendMessage(
                        'AvatarController',
                        'TriggerGesture',
                        event.data.payload.gesture
                    );
                    break;
                    
                case 'CHANGE_AVATAR':
                    unityInstance.SendMessage(
                        'AvatarManager',
                        'SwitchAvatar',
                        event.data.payload.avatarName
                    );
                    break;
            }
        });
        
        // Initialize Unity
        createUnityInstance(document.querySelector("#unity-canvas"), {
            dataUrl: "Build/WebGL.data",
            frameworkUrl: "Build/WebGL.framework.js",
            codeUrl: "Build/WebGL.wasm",
            streamingAssetsUrl: "StreamingAssets",
            companyName: "VaktaAI",
            productName: "AI Tutor Avatar",
            productVersion: "1.0",
        }).then((instance) => {
            unityInstance = instance;
            // Wait a bit for Unity to fully initialize
            setTimeout(() => OnUnityReady(), 2000);
        }).catch((message) => {
            console.error("Unity initialization failed:", message);
        });
    </script>
</body>
</html>
```

## ğŸ® Step 2: React Component for Unity Avatar

### **2.1 Create Unity Avatar Component**
```typescript
// client/src/components/ai-tutor/UnityAvatar.tsx

import React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';
import { Loader2 } from 'lucide-react';

export interface UnityAvatarHandle {
  sendAudioToAvatar: (audioBase64: string, emotion?: string) => void;
  setEmotion: (emotion: string) => void;
  triggerGesture: (gesture: string) => void;
  changeAvatar: (avatarName: 'priya' | 'amit') => void;
  isReady: boolean;
}

interface UnityAvatarProps {
  className?: string;
  defaultAvatar?: 'priya' | 'amit';
  onReady?: () => void;
  onMessage?: (message: any) => void;
}

const UnityAvatar = forwardRef<UnityAvatarHandle, UnityAvatarProps>(
  ({ className = '', defaultAvatar = 'priya', onReady, onMessage }, ref) => {
    const iframeRef = useRef<HTMLIFrameElement>(null);
    const [isLoading, setIsLoading] = useState(true);
    const [isUnityReady, setIsUnityReady] = useState(false);
    const [error, setError] = useState<string | null>(null);

    // Message handler from Unity
    useEffect(() => {
      const handleMessage = (event: MessageEvent) => {
        // Security: Check origin if needed
        // if (event.origin !== window.location.origin) return;

        if (event.data.type === 'UNITY_READY') {
          console.log('Unity Avatar is ready!');
          setIsUnityReady(true);
          setIsLoading(false);
          onReady?.();
        } else if (event.data.type === 'UNITY_MESSAGE') {
          onMessage?.(event.data.payload);
        }
      };

      window.addEventListener('message', handleMessage);
      
      // Timeout for Unity loading
      const timeout = setTimeout(() => {
        if (!isUnityReady) {
          setError('Unity Avatar loading timeout');
          setIsLoading(false);
        }
      }, 30000); // 30 seconds timeout

      return () => {
        window.removeEventListener('message', handleMessage);
        clearTimeout(timeout);
      };
    }, [isUnityReady, onReady, onMessage]);

    // Send message to Unity
    const sendMessageToUnity = (type: string, payload: any) => {
      if (iframeRef.current?.contentWindow && isUnityReady) {
        iframeRef.current.contentWindow.postMessage(
          { type, payload },
          '*'
        );
      } else {
        console.warn('Unity not ready or iframe not loaded');
      }
    };

    // Expose methods to parent component
    useImperativeHandle(ref, () => ({
      sendAudioToAvatar: (audioBase64: string, emotion?: string) => {
        sendMessageToUnity('PLAY_TTS_AUDIO', { audioData: audioBase64 });
        if (emotion) {
          sendMessageToUnity('SET_EMOTION', { emotion });
        }
      },
      setEmotion: (emotion: string) => {
        sendMessageToUnity('SET_EMOTION', { emotion });
      },
      triggerGesture: (gesture: string) => {
        sendMessageToUnity('TRIGGER_GESTURE', { gesture });
      },
      changeAvatar: (avatarName: 'priya' | 'amit') => {
        sendMessageToUnity('CHANGE_AVATAR', { avatarName });
      },
      isReady: isUnityReady
    }));

    // Handle iframe load error
    const handleIframeError = () => {
      setError('Failed to load Unity Avatar');
      setIsLoading(false);
    };

    return (
      <div className={`relative ${className}`}>
        {/* Loading overlay */}
        {isLoading && (
          <div className="absolute inset-0 bg-gray-900 bg-opacity-75 flex items-center justify-center z-10">
            <div className="text-center">
              <Loader2 className="w-8 h-8 animate-spin text-white mb-2 mx-auto" />
              <p className="text-white text-sm">Loading AI Tutor Avatar...</p>
            </div>
          </div>
        )}

        {/* Error state */}
        {error && (
          <div className="absolute inset-0 bg-red-50 flex items-center justify-center z-10">
            <div className="text-center p-4">
              <p className="text-red-600 mb-2">{error}</p>
              <button
                onClick={() => window.location.reload()}
                className="px-4 py-2 bg-red-600 text-white rounded hover:bg-red-700"
              >
                Reload
              </button>
            </div>
          </div>
        )}

        {/* Unity iframe */}
        <iframe
          ref={iframeRef}
          src="/unity-avatar/index.html"
          className="w-full h-full border-0"
          style={{
            display: 'block',
            minHeight: '400px'
          }}
          title="AI Tutor Avatar"
          allow="autoplay"
          onError={handleIframeError}
          sandbox="allow-scripts allow-same-origin"
        />
      </div>
    );
  }
);

UnityAvatar.displayName = 'UnityAvatar';

export default UnityAvatar;
```

## ğŸ’¬ Step 3: Integrate with AI Tutor Chat

### **3.1 Update AI Tutor Chat Component**
```typescript
// client/src/components/ai-tutor/AITutorChat.tsx

import React, { useRef, useState, useEffect } from 'react';
import UnityAvatar, { UnityAvatarHandle } from './UnityAvatar';
import { useQuery, useMutation } from '@tanstack/react-query';
import { api } from '@/lib/api';

interface Message {
  id: string;
  role: 'user' | 'assistant';
  content: string;
  emotion?: string;
  audioUrl?: string;
}

export default function AITutorChat() {
  const unityAvatarRef = useRef<UnityAvatarHandle>(null);
  const [messages, setMessages] = useState<Message[]>([]);
  const [currentPersona, setCurrentPersona] = useState<'priya' | 'amit'>('priya');
  const [isAvatarReady, setIsAvatarReady] = useState(false);
  const [inputMessage, setInputMessage] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);

  // Get chat session
  const { data: chatSession } = useQuery({
    queryKey: ['tutor-session'],
    queryFn: async () => {
      const response = await api.post('/api/tutor/session', {
        subject: 'Physics',
        level: 'intermediate',
        topic: 'Electricity',
        language: 'en'
      });
      return response.data;
    }
  });

  // TTS mutation
  const ttsMutation = useMutation({
    mutationFn: async ({ text, emotion }: { text: string; emotion?: string }) => {
      const response = await fetch('/api/tutor/tts', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          text,
          language: 'en-IN',
          emotion,
          voice: currentPersona,
          intent: 'teaching'
        })
      });
      
      if (!response.ok) throw new Error('TTS failed');
      
      const audioBlob = await response.blob();
      return { audioBlob, emotion };
    },
    onSuccess: async ({ audioBlob, emotion }) => {
      // Convert blob to base64
      const reader = new FileReader();
      reader.onloadend = () => {
        const base64Audio = reader.result?.toString().split(',')[1];
        if (base64Audio && unityAvatarRef.current?.isReady) {
          unityAvatarRef.current.sendAudioToAvatar(base64Audio, emotion);
        }
      };
      reader.readAsDataURL(audioBlob);
    }
  });

  // Send message and get AI response
  const sendMessage = async () => {
    if (!inputMessage.trim() || !chatSession) return;
    
    setIsProcessing(true);
    
    // Add user message
    const userMessage: Message = {
      id: Date.now().toString(),
      role: 'user',
      content: inputMessage
    };
    setMessages(prev => [...prev, userMessage]);
    setInputMessage('');

    try {
      // Get AI response (streaming)
      const response = await fetch(`/api/chats/${chatSession.chat.id}/stream?message=${encodeURIComponent(inputMessage)}`);
      const reader = response.body?.getReader();
      const decoder = new TextDecoder();
      
      let assistantMessage = '';
      let emotion = 'neutral';
      
      if (reader) {
        while (true) {
          const { done, value } = await reader.read();
          if (done) break;
          
          const chunk = decoder.decode(value);
          const lines = chunk.split('\n');
          
          for (const line of lines) {
            if (line.startsWith('data: ')) {
              try {
                const data = JSON.parse(line.slice(6));
                if (data.content) {
                  assistantMessage += data.content;
                }
                if (data.metadata?.emotion) {
                  emotion = data.metadata.emotion;
                }
              } catch (e) {
                console.error('Parse error:', e);
              }
            }
          }
        }
      }
      
      // Add assistant message
      const aiMessage: Message = {
        id: (Date.now() + 1).toString(),
        role: 'assistant',
        content: assistantMessage,
        emotion
      };
      setMessages(prev => [...prev, aiMessage]);
      
      // Generate and play TTS
      await ttsMutation.mutateAsync({ 
        text: assistantMessage, 
        emotion 
      });
      
    } catch (error) {
      console.error('Error sending message:', error);
    } finally {
      setIsProcessing(false);
    }
  };

  // Quick actions
  const handleQuickAction = (action: string) => {
    if (!unityAvatarRef.current?.isReady) return;
    
    switch(action) {
      case 'wave':
        unityAvatarRef.current.triggerGesture('wave');
        break;
      case 'think':
        unityAvatarRef.current.setEmotion('thinking');
        break;
      case 'explain':
        unityAvatarRef.current.triggerGesture('explaining');
        break;
    }
  };

  // Avatar ready handler
  const handleAvatarReady = () => {
    setIsAvatarReady(true);
    console.log('Avatar is ready for interaction!');
    
    // Send initial greeting
    if (unityAvatarRef.current) {
      unityAvatarRef.current.setEmotion('happy');
      ttsMutation.mutate({ 
        text: `Hello! I'm ${currentPersona === 'priya' ? 'Priya' : 'Amit'}, your AI tutor. How can I help you today?`,
        emotion: 'happy'
      });
    }
  };

  // Handle avatar change
  const changeAvatar = (avatar: 'priya' | 'amit') => {
    setCurrentPersona(avatar);
    if (unityAvatarRef.current?.isReady) {
      unityAvatarRef.current.changeAvatar(avatar);
    }
  };

  return (
    <div className="flex h-screen bg-gray-50">
      {/* Left Panel - Unity Avatar */}
      <div className="w-1/2 h-full relative bg-gradient-to-b from-purple-50 to-blue-50 border-r">
        {/* Avatar Container */}
        <div className="h-3/4">
          <UnityAvatar
            ref={unityAvatarRef}
            className="w-full h-full"
            defaultAvatar={currentPersona}
            onReady={handleAvatarReady}
            onMessage={(msg) => console.log('Unity message:', msg)}
          />
        </div>

        {/* Avatar Controls */}
        <div className="absolute bottom-0 left-0 right-0 p-4 bg-white bg-opacity-90">
          <div className="flex gap-2 mb-3">
            <button
              onClick={() => changeAvatar('priya')}
              className={`flex-1 py-2 px-4 rounded-lg transition ${
                currentPersona === 'priya'
                  ? 'bg-purple-600 text-white'
                  : 'bg-gray-200 hover:bg-gray-300'
              }`}
            >
              ğŸ‘©â€ğŸ« Priya (Female)
            </button>
            <button
              onClick={() => changeAvatar('amit')}
              className={`flex-1 py-2 px-4 rounded-lg transition ${
                currentPersona === 'amit'
                  ? 'bg-blue-600 text-white'
                  : 'bg-gray-200 hover:bg-gray-300'
              }`}
            >
              ğŸ‘¨â€ğŸ« Amit (Male)
            </button>
          </div>

          {/* Quick Actions */}
          <div className="flex gap-2">
            <button
              onClick={() => handleQuickAction('wave')}
              className="px-3 py-1 bg-green-500 text-white rounded text-sm hover:bg-green-600"
              disabled={!isAvatarReady}
            >
              ğŸ‘‹ Wave
            </button>
            <button
              onClick={() => handleQuickAction('think')}
              className="px-3 py-1 bg-yellow-500 text-white rounded text-sm hover:bg-yellow-600"
              disabled={!isAvatarReady}
            >
              ğŸ¤” Think
            </button>
            <button
              onClick={() => handleQuickAction('explain')}
              className="px-3 py-1 bg-blue-500 text-white rounded text-sm hover:bg-blue-600"
              disabled={!isAvatarReady}
            >
              ğŸ’¡ Explain
            </button>
          </div>

          {/* Avatar Status */}
          <div className="mt-2 text-sm">
            Status: {isAvatarReady ? 
              <span className="text-green-600">âœ… Ready</span> : 
              <span className="text-yellow-600">â³ Loading...</span>
            }
          </div>
        </div>
      </div>

      {/* Right Panel - Chat Interface */}
      <div className="w-1/2 h-full flex flex-col">
        {/* Chat Header */}
        <div className="bg-white border-b p-4">
          <h2 className="text-xl font-semibold">AI Tutor Chat</h2>
          <p className="text-sm text-gray-600">
            Subject: Physics | Topic: Electricity | Level: Intermediate
          </p>
        </div>

        {/* Messages Container */}
        <div className="flex-1 overflow-y-auto p-4 space-y-4">
          {messages.map((message) => (
            <div
              key={message.id}
              className={`flex ${
                message.role === 'user' ? 'justify-end' : 'justify-start'
              }`}
            >
              <div
                className={`max-w-md p-3 rounded-lg ${
                  message.role === 'user'
                    ? 'bg-purple-600 text-white'
                    : 'bg-white border shadow-sm'
                }`}
              >
                <p className="text-sm font-medium mb-1">
                  {message.role === 'user' ? 'You' : currentPersona === 'priya' ? 'Priya' : 'Amit'}
                </p>
                <p>{message.content}</p>
                {message.emotion && (
                  <span className="text-xs opacity-70 mt-1 block">
                    Emotion: {message.emotion}
                  </span>
                )}
              </div>
            </div>
          ))}
          
          {isProcessing && (
            <div className="flex justify-start">
              <div className="bg-gray-100 p-3 rounded-lg">
                <div className="flex space-x-2">
                  <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce"></div>
                  <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce delay-100"></div>
                  <div className="w-2 h-2 bg-gray-400 rounded-full animate-bounce delay-200"></div>
                </div>
              </div>
            </div>
          )}
        </div>

        {/* Input Section */}
        <div className="border-t bg-white p-4">
          <div className="flex gap-2">
            <input
              type="text"
              value={inputMessage}
              onChange={(e) => setInputMessage(e.target.value)}
              onKeyPress={(e) => e.key === 'Enter' && !e.shiftKey && sendMessage()}
              placeholder="Type your question..."
              className="flex-1 px-4 py-2 border rounded-lg focus:outline-none focus:border-purple-500"
              disabled={!isAvatarReady || isProcessing}
            />
            <button
              onClick={sendMessage}
              disabled={!isAvatarReady || isProcessing || !inputMessage.trim()}
              className="px-6 py-2 bg-purple-600 text-white rounded-lg hover:bg-purple-700 disabled:opacity-50 disabled:cursor-not-allowed"
            >
              Send
            </button>
          </div>
          
          {/* Quick Tools */}
          <div className="flex gap-2 mt-3">
            <button className="text-sm px-3 py-1 bg-gray-100 rounded hover:bg-gray-200">
              ğŸ’¡ Hint
            </button>
            <button className="text-sm px-3 py-1 bg-gray-100 rounded hover:bg-gray-200">
              ğŸ“– Example
            </button>
            <button className="text-sm px-3 py-1 bg-gray-100 rounded hover:bg-gray-200">
              ğŸ“ Summary
            </button>
            <button className="text-sm px-3 py-1 bg-gray-100 rounded hover:bg-gray-200">
              ğŸ¯ Quiz
            </button>
          </div>
        </div>
      </div>
    </div>
  );
}
```

## ğŸ”Š Step 4: Backend TTS Integration Update

### **4.1 Update TTS Endpoint for Unity**
```typescript
// server/api/tutor/tts.ts

import { Router } from 'express';
import { requireAuth } from '../../middleware/auth';
import { generateTTS } from '../../services/voice.service';

const router = Router();

router.post('/tts', requireAuth, async (req, res) => {
  const { text, language, emotion, voice, intent } = req.body;

  try {
    // Process text for better lip-sync
    const processedText = preprocessForLipSync(text);
    
    // Detect or use provided emotion
    const finalEmotion = emotion || detectEmotion(text, intent);
    
    // Generate TTS based on voice selection
    const audioBuffer = await generateTTS({
      text: processedText,
      voice: voice || 'priya',
      language: language || 'en-IN',
      emotion: finalEmotion,
      // Adjust prosody based on emotion
      prosody: getProsodySettings(finalEmotion)
    });
    
    // Return audio as blob
    res.set({
      'Content-Type': 'audio/mpeg',
      'Content-Length': audioBuffer.length,
      'X-Emotion': finalEmotion
    });
    
    res.send(audioBuffer);
    
  } catch (error) {
    console.error('TTS generation failed:', error);
    res.status(500).json({ 
      error: 'TTS generation failed',
      message: error.message 
    });
  }
});

// Helper functions
function preprocessForLipSync(text: string): string {
  // Convert mathematical expressions to speakable format
  text = text.replace(/(\d+)\s*\+\s*(\d+)/g, '$1 plus $2');
  text = text.replace(/(\d+)\s*\-\s*(\d+)/g, '$1 minus $2');
  text = text.replace(/(\d+)\s*\*\s*(\d+)/g, '$1 times $2');
  text = text.replace(/(\d+)\s*\/\s*(\d+)/g, '$1 divided by $2');
  text = text.replace(/V\s*=\s*IR/g, 'V equals I into R');
  
  // Add pauses for better comprehension
  text = text.replace(/\./g, '. <break time="300ms"/>');
  text = text.replace(/,/g, ', <break time="150ms"/>');
  text = text.replace(/:/g, ': <break time="200ms"/>');
  
  return text;
}

function detectEmotion(text: string, intent?: string): string {
  // Simple emotion detection based on content
  const lowerText = text.toLowerCase();
  
  if (intent === 'greeting' || lowerText.includes('hello') || lowerText.includes('welcome')) {
    return 'happy';
  }
  if (lowerText.includes('think') || lowerText.includes('let me') || lowerText.includes('hmm')) {
    return 'thinking';
  }
  if (lowerText.includes('excellent') || lowerText.includes('great job') || lowerText.includes('correct')) {
    return 'excited';
  }
  if (lowerText.includes('try again') || lowerText.includes('not quite')) {
    return 'encouraging';
  }
  
  return 'neutral';
}

function getProsodySettings(emotion: string) {
  const settings = {
    happy: { pitch: 1.1, rate: 1.05, volume: 1.1 },
    sad: { pitch: 0.9, rate: 0.95, volume: 0.9 },
    excited: { pitch: 1.2, rate: 1.1, volume: 1.2 },
    thinking: { pitch: 1.0, rate: 0.9, volume: 1.0 },
    encouraging: { pitch: 1.05, rate: 1.0, volume: 1.05 },
    neutral: { pitch: 1.0, rate: 1.0, volume: 1.0 }
  };
  
  return settings[emotion] || settings.neutral;
}

export default router;
```

## âš™ï¸ Step 5: Configuration & Optimization

### **5.1 Vite Configuration for Unity Files**
```typescript
// client/vite.config.ts
import { defineConfig } from 'vite';
import react from '@vitejs/plugin-react';

export default defineConfig({
  plugins: [react()],
  server: {
    port: 5173,
    // Properly serve Unity files
    headers: {
      'Cross-Origin-Embedder-Policy': 'require-corp',
      'Cross-Origin-Opener-Policy': 'same-origin',
    }
  },
  build: {
    // Exclude Unity files from Vite processing
    assetsInlineLimit: 0,
    rollupOptions: {
      output: {
        manualChunks: {
          'react-vendor': ['react', 'react-dom'],
          'ai-tutor': ['./src/components/ai-tutor/AITutorChat.tsx']
        }
      }
    }
  },
  // Handle Unity file types
  assetsInclude: ['**/*.data', '**/*.wasm', '**/*.framework.js']
});
```

### **5.2 Express Static File Serving**
```typescript
// server/index.ts
import express from 'express';
import compression from 'compression';
import path from 'path';

const app = express();

// Compression for Unity files
app.use(compression({
  filter: (req, res) => {
    // Compress Unity files
    if (req.url.includes('/unity-avatar/')) {
      return true;
    }
    return compression.filter(req, res);
  }
}));

// Serve Unity WebGL files with proper headers
app.use('/unity-avatar', express.static(path.join(__dirname, '../client/public/unity-avatar'), {
  setHeaders: (res, filePath) => {
    // Set caching for Unity files
    if (filePath.endsWith('.data') || filePath.endsWith('.wasm')) {
      res.set('Cache-Control', 'public, max-age=31536000'); // 1 year
    }
    
    // Set CORS headers if needed
    res.set('Access-Control-Allow-Origin', '*');
    
    // Content encoding for compressed Unity files
    if (filePath.endsWith('.br')) {
      res.set('Content-Encoding', 'br');
    } else if (filePath.endsWith('.gz')) {
      res.set('Content-Encoding', 'gzip');
    }
  }
}));
```

## ğŸ“± Step 6: Mobile Responsive Design

### **6.1 Responsive Unity Avatar Component**
```typescript
// client/src/components/ai-tutor/ResponsiveUnityAvatar.tsx

import React from 'react';
import UnityAvatar from './UnityAvatar';
import { useMediaQuery } from '@/hooks/useMediaQuery';

export default function ResponsiveAITutor() {
  const isMobile = useMediaQuery('(max-width: 768px)');
  const isTablet = useMediaQuery('(max-width: 1024px)');

  if (isMobile) {
    // Mobile Layout - Avatar as floating widget
    return (
      <div className="relative h-screen">
        {/* Chat takes full screen */}
        <div className="h-full">
          {/* Chat content */}
        </div>
        
        {/* Floating Avatar */}
        <div className="fixed bottom-20 right-4 w-32 h-32 rounded-full overflow-hidden shadow-lg z-50">
          <UnityAvatar className="w-full h-full" />
        </div>
      </div>
    );
  }

  if (isTablet) {
    // Tablet Layout - Avatar on top
    return (
      <div className="flex flex-col h-screen">
        <div className="h-64">
          <UnityAvatar className="w-full h-full" />
        </div>
        <div className="flex-1">
          {/* Chat content */}
        </div>
      </div>
    );
  }

  // Desktop Layout - Side by side
  return (
    <div className="flex h-screen">
      <div className="w-1/2">
        <UnityAvatar className="w-full h-full" />
      </div>
      <div className="w-1/2">
        {/* Chat content */}
      </div>
    </div>
  );
}
```

## ğŸ› Step 7: Error Handling & Fallbacks

### **7.1 WebGL Detection & Fallback**
```typescript
// client/src/utils/webgl-detector.ts

export function isWebGLAvailable(): boolean {
  try {
    const canvas = document.createElement('canvas');
    return !!(
      window.WebGLRenderingContext &&
      (canvas.getContext('webgl') || canvas.getContext('experimental-webgl'))
    );
  } catch (e) {
    return false;
  }
}

export function getWebGLErrorMessage(): string {
  if (!window.WebGLRenderingContext) {
    return 'Your browser does not support WebGL';
  }
  
  const canvas = document.createElement('canvas');
  const gl = canvas.getContext('webgl') || canvas.getContext('experimental-webgl');
  
  if (!gl) {
    return 'Your browser supports WebGL but it is disabled or unavailable';
  }
  
  return '';
}

// Usage in component
if (!isWebGLAvailable()) {
  return (
    <div className="flex items-center justify-center h-full bg-gray-100">
      <div className="text-center p-6">
        <img src="/avatars/priya-static.png" alt="AI Tutor" className="w-48 h-48 mx-auto mb-4" />
        <p className="text-gray-600">{getWebGLErrorMessage()}</p>
        <p className="text-sm text-gray-500 mt-2">
          The 3D avatar requires WebGL. You can still use the chat functionality.
        </p>
      </div>
    </div>
  );
}
```

## ğŸš€ Step 8: Deployment Checklist

### **8.1 Pre-deployment Steps**
```bash
# 1. Optimize Unity build
# In Unity: File > Build Settings > Player Settings
# - Set Compression Format: Brotli
# - Enable Exception Support: None (smaller build)
# - Set Memory Size: 256 MB

# 2. Compress Unity files
cd client/public/unity-avatar/Build
brotli -q 11 WebGL.data -o WebGL.data.br
brotli -q 11 WebGL.wasm -o WebGL.wasm.br
brotli -q 11 WebGL.framework.js -o WebGL.framework.js.br

# 3. Update index.html to use compressed files
# Change: dataUrl: "Build/WebGL.data.br"
# Change: frameworkUrl: "Build/WebGL.framework.js.br"
# Change: codeUrl: "Build/WebGL.wasm.br"
```

### **8.2 Nginx Configuration**
```nginx
server {
    # Serve Brotli compressed Unity files
    location ~ \.(data|wasm|framework\.js)\.br$ {
        gzip off;
        add_header Content-Encoding br;
        add_header Cache-Control "public, max-age=31536000";
        
        # Set correct MIME types
        location ~ \.data\.br$ {
            add_header Content-Type application/octet-stream;
        }
        location ~ \.wasm\.br$ {
            add_header Content-Type application/wasm;
        }
        location ~ \.js\.br$ {
            add_header Content-Type application/javascript;
        }
    }
    
    # Enable CORS for Unity files
    location /unity-avatar/ {
        add_header Access-Control-Allow-Origin *;
        add_header Cross-Origin-Embedder-Policy require-corp;
        add_header Cross-Origin-Opener-Policy same-origin;
    }
}
```

## âœ… Step 9: Testing

### **9.1 Test Checklist**
```typescript
// client/src/tests/unity-integration.test.ts

describe('Unity Avatar Integration', () => {
  test('Unity iframe loads successfully', async () => {
    // Check iframe loads
  });
  
  test('Unity sends ready message', async () => {
    // Wait for UNITY_READY message
  });
  
  test('Audio plays with lip-sync', async () => {
    // Send audio and verify playback
  });
  
  test('Emotion changes reflect in avatar', async () => {
    // Test emotion changes
  });
  
  test('Avatar switching works', async () => {
    // Switch between Priya and Amit
  });
  
  test('Mobile responsive layout', async () => {
    // Test on different screen sizes
  });
  
  test('WebGL fallback for unsupported browsers', async () => {
    // Test fallback mechanism
  });
});
```

## ğŸ“ˆ Performance Monitoring

```typescript
// Monitor Unity performance
const monitorUnityPerformance = () => {
  if (window.performance && window.performance.memory) {
    const memoryInfo = {
      usedJSHeapSize: (window.performance.memory.usedJSHeapSize / 1048576).toFixed(2) + ' MB',
      totalJSHeapSize: (window.performance.memory.totalJSHeapSize / 1048576).toFixed(2) + ' MB',
      jsHeapSizeLimit: (window.performance.memory.jsHeapSizeLimit / 1048576).toFixed(2) + ' MB'
    };
    
    console.log('Unity Memory Usage:', memoryInfo);
  }
};

// Call every 10 seconds
setInterval(monitorUnityPerformance, 10000);
```

Ye complete step-by-step implementation follow karke aap successfully Unity WebGL avatar integrate kar sakte hain aapke VaktaAI platform me. Main points:

1. âœ… Unity files proper location pe place karo
2. âœ… PostMessage API se communication setup karo  
3. âœ… React component properly integrate karo
4. âœ… TTS audio pipeline connect karo
5. âœ… Error handling aur fallbacks implement karo
6. âœ… Mobile responsive design ensure karo

Koi specific issue aaye to batana, main help karunga! ğŸš€